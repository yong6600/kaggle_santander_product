{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep 1: melt and append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load full data\n",
    "trn = pd.read_csv('../input/train_ver2.csv')\n",
    "tst = pd.read_csv('../input/test_ver2.csv')\n",
    "labels = pd.read_csv('../input/labels.csv').astype(int)\n",
    "\n",
    "# prepare lag data\n",
    "trn_dates = ['2015-01-28','2015-02-28','2015-03-28','2015-04-28','2015-05-28']\n",
    "tst_dates = ['2016-01-28','2016-02-28','2016-03-28','2016-04-28','2016-05-28']\n",
    "\n",
    "temp = trn[trn['fecha_dato'] == '2015-06-28']['ncodpers']\n",
    "trn_ncodpers = temp[(labels[trn['fecha_dato'] == '2015-06-28'].sum(axis=1) > 0).values].values.tolist()\n",
    "tst_ncodpers = np.unique(tst['ncodpers']).tolist()\n",
    "\n",
    "trn_trim = trn[trn['fecha_dato'].isin(trn_dates)]\n",
    "trn_trim = trn_trim[trn_trim['ncodpers'].isin(trn_ncodpers)]\n",
    "tst_trim = trn[trn['fecha_dato'].isin(tst_dates)]\n",
    "tst_trim = tst_trim[tst_trim['ncodpers'].isin(tst_ncodpers)]\n",
    "\n",
    "# melt labels for trn\n",
    "\n",
    "fecha_dato = trn['fecha_dato']\n",
    "train_index = (labels[fecha_dato == '2015-06-28'].sum(axis=1) > 0)\n",
    "train_index = train_index[train_index == True]\n",
    "train = trn.ix[train_index.index]\n",
    "train.iloc[:,24:] = labels.ix[train_index.index]\n",
    "\n",
    "trn_june = []\n",
    "for ind, (run, row) in enumerate(train.iterrows()):\n",
    "    for i in range(24):\n",
    "        if row[24+i] == 1:\n",
    "            temp = row[:24].values.tolist()\n",
    "            temp.append(i)\n",
    "            trn_june.append(temp)\n",
    "            \n",
    "# define and save target separately\n",
    "target = pd.DataFrame(trn_june)[24].values.tolist()\n",
    "target = pd.DataFrame(target)\n",
    "print('# target shape : ({})'.format(len(target)))\n",
    "\n",
    "# make full data set \n",
    "trn_june = pd.DataFrame(trn_june, columns=trn.columns[:25]).iloc[:,:-1]\n",
    "trn = pd.concat([trn_trim, trn_june], axis=0)\n",
    "tst = pd.concat([tst_trim, tst], axis=0)\n",
    "print(trn.shape, tst.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep 2: Label Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean data\n",
    "skip_cols = ['fecha_dato','ncodpers']\n",
    "target_cols = ['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n",
    "               'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n",
    "               'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
    "               'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n",
    "               'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
    "               'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
    "               'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    "               'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']\n",
    "\n",
    "for col in trn.columns:\n",
    "    if col in skip_cols:\n",
    "        continue\n",
    "    \n",
    "    if col == 'ind_empleado':\n",
    "        trn[col].fillna('S', inplace=True)\n",
    "    elif col == 'age':\n",
    "        trn[col].replace(' NA',0,inplace=True)\n",
    "        trn[col] = trn[col].astype(str).astype(int)\n",
    "        trn[col] = trn[col].astype(str).astype(int)\n",
    "        continue\n",
    "    elif col == 'fecha_alta':\n",
    "        trn[col] = ((pd.to_datetime(trn['fecha_dato']) - pd.to_datetime(trn[col].fillna('2015-07-01')))/ np.timedelta64(1, 'D')).astype(int)\n",
    "        tst[col] = ((pd.to_datetime(tst['fecha_dato']) - pd.to_datetime(tst[col]))/np.timedelta64(1, 'D')).astype(int)\n",
    "        continue\n",
    "    elif col == 'antiguedad':\n",
    "        trn[col].replace('     NA',-1,inplace=True)\n",
    "        trn[col] = trn[col].astype(str).astype(int)\n",
    "        tst[col] = tst[col].astype(str).astype(int)\n",
    "        continue\n",
    "    elif col == 'ult_fec_cli_1t':\n",
    "        trn[col] = ((pd.to_datetime(trn['fecha_dato']) - pd.to_datetime(trn[col].fillna('2015-06-30')))/ np.timedelta64(1, 'D')).astype(int)\n",
    "        tst[col] = ((pd.to_datetime(tst['fecha_dato']) - pd.to_datetime(tst[col].fillna('2016-01-03')))/np.timedelta64(1, 'D')).astype(int)\n",
    "        continue\n",
    "    elif col == 'indrel_1mes':\n",
    "        tst[col].replace('1','1.0',inplace=True)\n",
    "        tst[col].replace('2','1.0',inplace=True)\n",
    "        tst[col].replace('2.0','1.0',inplace=True)\n",
    "        tst[col].replace(2.0,'1.0',inplace=True)\n",
    "        tst[col].replace('3','3.0',inplace=True)\n",
    "        tst[col].replace('4','3.0',inplace=True)\n",
    "        tst[col].replace(4.0,'3.0',inplace=True)\n",
    "        tst[col].replace('4.0','3.0',inplace=True)\n",
    "        tst[col].replace('P','3.0',inplace=True)\n",
    "    elif col == 'tiprel_1mes':\n",
    "        tst[col].replace('N','I',inplace=True)\n",
    "        tst[col].replace('R','P',inplace=True)\n",
    "    elif col == 'indresi':\n",
    "        trn[col].fillna('N',inplace=True)\n",
    "    elif col == 'indext':\n",
    "        trn[col].fillna('S',inplace=True)\n",
    "    elif col == 'indfall':\n",
    "        trn[col].fillna('N',inplace=True)\n",
    "    elif col == 'tipodom':\n",
    "        trn.drop([col], axis=1, inplace=True)\n",
    "        tst.drop([col], axis=1, inplace=True)\n",
    "        continue\n",
    "    elif col == 'ind_actividad_cliente':\n",
    "        trn[col].fillna(0.0, inplace=True)\n",
    "    elif col == 'renta':\n",
    "        tst[col].replace('         NA',0,inplace=True)\n",
    "        trn[col].fillna(-1, inplace=True)\n",
    "        tst[col].fillna(-1, inplace=True)\n",
    "        trn[col] = trn[col].astype(str).astype(float).astype(int)\n",
    "        tst[col] = tst[col].astype(str).astype(float).astype(int)\n",
    "        continue\n",
    "    elif col in target_cols:\n",
    "        trn[col].fillna(0, inplace=True)\n",
    "        trn[col] = trn[col].astype(int)\n",
    "        tst[col].fillna(0, inplace=True)\n",
    "        tst[col] = tst[col].astype(int)\n",
    "        \n",
    "    lb = LabelEncoder()\n",
    "    lb.fit(pd.concat([trn[col].astype(str), tst[col].astype(str)], axis=0))\n",
    "    trn[col] = lb.transform(trn[col].astype(str))\n",
    "    tst[col] = lb.transform(tst[col].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## prep 3: append lag\n",
    "    - for each ncodpers in June data, append Jan~May (48x5) to single June data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_june = trn[trn['fecha_dato'] == '2015-06-28'].drop(target_cols, axis=1)\n",
    "trn_othr = trn[trn['fecha_dato'] != '2015-06-28']\n",
    "tst_june = tst[tst['fecha_dato'] == '2016-06-28'].drop(target_cols, axis=1)\n",
    "tst_othr = tst[tst['fecha_dato'] != '2016-06-28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "drop_cols = ['fecha_dato','ncodpers']\n",
    "\n",
    "print('# Appending trn data.. {} rows'.format(trn_june.shape[0]))\n",
    "trn_append = []\n",
    "for i, ncodper in enumerate(trn_june['ncodpers']):\n",
    "    temp = trn_othr[trn_othr['ncodpers'] == ncodper].drop(drop_cols, axis=1)\n",
    "    if temp.shape[0] == 0:\n",
    "        row = ['NA']*225\n",
    "    else:\n",
    "        row = np.hstack([temp.shift(periods=i).iloc[-1,:] for i in range(temp.shape[0])]).tolist()\n",
    "    trn_append.append(trn_june.iloc[i].drop(drop_cols).values.tolist() + row)\n",
    "    \n",
    "    if i % int(trn_june.shape[0]/10) == 0:\n",
    "        print('# {} rows.. {} secs..'.format(i, round(time.time() - st),2))\n",
    "\n",
    "st = time.time()\n",
    "print('# Appending tst data.. {} rows'.format(tst_june.shape[0]))\n",
    "tst_append = []\n",
    "for i, ncodper in enumerate(tst_june['ncodpers']):\n",
    "    temp = tst_othr[tst_othr['ncodpers'] == ncodper].drop(drop_cols, axis=1)\n",
    "    if temp.shape[0] == 0:\n",
    "        row = ['NA']*225\n",
    "    else:\n",
    "        row = np.hstack([temp.shift(periods=i).iloc[-1,:] for i in range(temp.shape[0])]).tolist()\n",
    "    tst_append.append(tst_june.iloc[i].drop(drop_cols).values.tolist() + row)\n",
    "    \n",
    "    if i % int(tst_june.shape[0]/10) == 0:\n",
    "        print('# {} rows.. {} secs..'.format(i, round(time.time() - st),2))\n",
    "\n",
    "# 150 secs for trn\n",
    "# 9964 secs for tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colnames = trn_june.drop(drop_cols, axis=1).columns.values.tolist()\n",
    "suffixes = ['_lag_one','_lag_two','_lag_thr','_lag_fou','_lag_fiv']\n",
    "for suffix in suffixes:\n",
    "    for col in trn_othr.drop(drop_cols, axis=1).columns.values.tolist():\n",
    "        colnames.append(col+suffix)\n",
    "print(len(colnames))\n",
    "\n",
    "# initialize column names\n",
    "trn = pd.DataFrame(trn_append, columns=colnames)\n",
    "tst = pd.DataFrame(tst_append, columns=colnames)\n",
    "print('# trn : {} | tst : {}'.format(trn.shape, tst.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn.to_csv('../input/train_append_lb_lag.csv', index=False)\n",
    "tst.to_csv('../input/test_append_lb_lag.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
